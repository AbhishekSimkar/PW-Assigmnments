{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85cd860b-d425-41fd-a63b-451dc178364b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values?'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "311179fb-d147-4427-99d4-e5a03d24a60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If there is an empty location due to some reasons where there should be some values, it is called missing values.\\nTo compute the expression or task more near to correct value we should handle it.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''If there is an empty location due to some reasons where there should be some values, it is called missing values.\n",
    "To compute the expression or task more near to correct value we should handle it.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c43ce3b-9341-48fa-8aba-a95fbfc9e460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2: List down techniques used to handle missing data.  Give an example of each with python code.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'2: List down techniques used to handle missing data.  Give an example of each with python code.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5e2d617-ff87-48a9-9f0a-456dd7bfa07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The techniques are:\\n1) Mean value imputation\\n2) Median value imputation \\n3) Mode value imputation'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''The techniques are:\n",
    "1) Mean value imputation\n",
    "2) Median value imputation \n",
    "3) Mode value imputation'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504875c4-c1f9-4a2a-9e9f-ae5258633082",
   "metadata": {},
   "source": [
    "## Mean Value imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f586968c-9304-4b5a-a048-31296f8551ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "df=sns.load_dataset('titanic')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0659b43d-b2b6-4e32-b0a1-5be196e1f8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age_new']= df['age'].fillna(df['age'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56744354-06fb-4356-af6a-2f9d3ed7cb2b",
   "metadata": {},
   "source": [
    "## Median value imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a45982f6-4c07-4484-a833-1d45ba9654d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age_new2']= df['age'].fillna(df['age'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fc9d96-42a7-4235-82cb-7dd01446f396",
   "metadata": {},
   "source": [
    "## Mode value imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17446129-661b-456d-a070-bfabdee7788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_value=df[df['embarked'].notna()]['embarked'].mode()[0]\n",
    "df['new_embarked']=df['embarked'].fillna('mode_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ba6c060-6c36-4c54-8977-3b4e9ec3fa34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3: Explain the imbalanced data. What will happen if imbalanced data is not handled?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'3: Explain the imbalanced data. What will happen if imbalanced data is not handled?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c8e27d8-77ba-4d6a-bf9a-43ede76e6149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The dataset having right or left skewness or having outliers is called imbalanced data. This imbalance can lead to inaccurate results.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'The dataset having right or left skewness or having outliers is called imbalanced data. This imbalance can lead to inaccurate results.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98599911-729f-44c4-b8c0-dc23c752436f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and downsampling are required.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and downsampling are required.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87c8f67e-776e-44ea-93fd-7b03b26af138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Up-Sampling: In this method we increase the no of elements of the values which are in minority. Example: suppose we have n ratio as 0.6\\nDown-Sampling: In this method we decrease the no of elements of the values which are in majority.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Up-Sampling: In this method we increase the no of elements of the values which are in minority. Example: suppose we have n ratio as 0.6\n",
    "Down-Sampling: In this method we decrease the no of elements of the values which are in majority.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00c754a2-cb41-4b16-9fcb-54c0ae60a44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5: What is data Augmentation? Explain SMOTE.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'5: What is data Augmentation? Explain SMOTE.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f703311-2774-4447-adb3-e44561fdbb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data augmentation is a technique of artificially increasing the training set by creating modified copies of a dataset using existing data.\\nSMOTE (Synthetic Minority Over-sampling Technique) is a technique used in machine learning to address imbalanced datasets where the minority class has significantly fewer instances than the majority class. SMOTE involves generating synthetic instances of the minority class by interpolating between existing instances.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Data augmentation is a technique of artificially increasing the training set by creating modified copies of a dataset using existing data.\n",
    "SMOTE (Synthetic Minority Over-sampling Technique) is a technique used in machine learning to address imbalanced datasets where the minority class has significantly fewer instances than the majority class. SMOTE involves generating synthetic instances of the minority class by interpolating between existing instances.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cd6eace-6680-4bb6-9a4e-da8a60840cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6: What are outliers in a dataset? Why is it essential to handle outliers?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'6: What are outliers in a dataset? Why is it essential to handle outliers?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "978c3c2d-d2d9-44bb-8c24-30cfd276420a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Outliers are the extreme values in a dataset which disturbs normal distribution. It is essential to handle it because it changes the major statistical properties like mean, median etc by high value. Hence, we generally get incoorect results.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Outliers are the extreme values in a dataset which disturbs normal distribution. It is essential to handle it because it changes the major statistical properties like mean, median etc by high value. Hence, we generally get incoorect results.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34c76577-ab6a-4878-af6f-341308f000d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "689f2a2d-ad85-4db4-a246-4ef285a1036e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The techniques are:\\n1) Mean value imputation.\\n2) Median value imputation.\\n3) Mode value imputation.\\n4) SMOTE.\\n5) Data Interpolation.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' The techniques are:\n",
    "1) Mean value imputation.\n",
    "2) Median value imputation.\n",
    "3) Mode value imputation.\n",
    "4) SMOTE.\n",
    "5) Data Interpolation.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc9a2a99-8845-4a5c-ba10-fdf102c3ada9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8: You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'8: You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07d93709-f84b-48e4-9c61-1eb7c99a3b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Firstly we will find which values are missing. For random position, we will fill those missing positions with the mean, median or mode of the dataset. If there is a pattern then we will analyze the pattern and work futher on it with suitable technique.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Firstly we will find which values are missing. For random position, we will fill those missing positions with the mean, median or mode of the dataset. If there is a pattern then we will analyze the pattern and work futher on it with suitable technique.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b5a2a6f-6973-483e-80ea-12cf15ace010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3419b64b-a9ce-484c-8f48-5af285016714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We can do down sampling of the data'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'We can do down sampling of the data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df093ec0-8838-4305-a0b1-e6c695e991e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the dataset and up-sample the minority class?'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the dataset and up-sample the minority class?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4fb6629-75b7-40cb-b33e-53e4aae300c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We can do up sampling of data.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'We can do up sampling of data.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b78b4a5-e890-4d8f-bcff-330870bd55e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
